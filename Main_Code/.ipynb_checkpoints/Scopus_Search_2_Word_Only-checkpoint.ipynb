{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use multiple Scopus Author IDs to retrieve lists of articles by author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:param.panel_extension: A HoloViz extension was loaded previously. This means the extension is already initialized and the following Panel extensions could not be properly loaded: ['plotly']. If you are loading custom extensions with pn.extension(...) ensure that this is called before any other HoloViz extension such as hvPlot or HoloViews.\n"
     ]
    }
   ],
   "source": [
    "# Dependencies\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from config import api_key\n",
    "from pandas.io.json import json_normalize  \n",
    "import nltk\n",
    "import re\n",
    "import io\n",
    "from nltk.corpus import stopwords, reuters\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from wordcloud import WordCloud\n",
    "import panel as pn\n",
    "import panel.widgets \n",
    "from pathlib import Path\n",
    "from panel.interact import interact\n",
    "\n",
    "import hvplot.pandas\n",
    "import param\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML\n",
    "import time\n",
    "import datetime as dt\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "pn.extension('plotly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching server at http://localhost:53275\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bokeh.server.server.Server at 0x1d7207cf648>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Search request function \n",
    "\n",
    "class search_scopus_dash(param.Parameterized):\n",
    "    \n",
    "    Query  = param.String(default=\"Nanosafety\", doc=\"Insert query term(s)\")\n",
    "    \n",
    "    Year_Range = param.Range((2005, 2010), bounds=(1970, 2021))\n",
    "    \n",
    "    generate_sample_df = param.Action(lambda self: self.update_sample_df(), label=\"Generate Data\", doc=\"\"\"\n",
    "      An action callback which will update the sample_df.\"\"\")\n",
    "    \n",
    "    sample_df = param.DataFrame(doc=\"\"\"\n",
    "      The current dataframe of samples.\"\"\")\n",
    "    \n",
    "    file_name = param.String(default=\"data.csv\", doc=\"\"\"\n",
    "      The filename to save to.\"\"\")\n",
    "    \n",
    "    def __init__(self, **params):\n",
    "        super().__init__(**params)\n",
    "        self.update_sample_df()\n",
    "        self.download = pn.widgets.FileDownload(name=\"Download Data\", filename=self.file_name, callback=self._download_callback, button_type=\"primary\")\n",
    "        self.table = pn.widgets.DataFrame(self.sample_df.head(10), height=360)\n",
    "        \n",
    "        \n",
    "    @pn.depends('file_name', watch=True)\n",
    "    def _update_filename(self):\n",
    "        self.download.filename = self.file_name\n",
    "    \n",
    "    def _download_callback(self):\n",
    "        \"\"\"\n",
    "        A FileDownload callback will return a file-like object which can be serialized\n",
    "        and sent to the client.\n",
    "        \"\"\"\n",
    "        self.download.filename = self.file_name\n",
    "        sio = io.StringIO()\n",
    "        self.sample_df.to_csv(sio, index=False)\n",
    "        sio.seek(0)\n",
    "        return sio\n",
    "    \n",
    "    \n",
    "    \n",
    "    @param.depends(\"Query\", \"Year_Range\")\n",
    "    def search_request_funt(self):\n",
    "    \n",
    "        scopus_search_appended_df = pd.DataFrame()\n",
    "    \n",
    "        if self.Year_Range[0] == self.Year_Range[1]:\n",
    "            date = str(self.Year_Range[0])\n",
    "        else: \n",
    "            date = str(self.Year_Range[0]) + \"-\" + str(self.Year_Range[1])\n",
    "        # Declare necessary parameters for Scopus request API search tool\n",
    "        cursor = \"*\"\n",
    "        field = \"prism:coverDate,dc:title,dc:description\"\n",
    "        url = \"http://api.elsevier.com/content/search/scopus?\"\n",
    "        headers = {\"X-ELS-APIKey\": api_key, 'Accept':'application/json'}\n",
    "        parameters = {\"query\": self.Query, \"view\": \"Complete\", \"date\": date, \"field\": field, \"cursor\": cursor}\n",
    "        article_response = requests.get(url, headers=headers, params=parameters)\n",
    "        article_response_json = article_response.json()\n",
    "        total_results = int(article_response_json['search-results']['opensearch:totalResults'])\n",
    "        while article_response_json['search-results'].get('entry') is not None:\n",
    "            url = \"http://api.elsevier.com/content/search/scopus?\"\n",
    "            parameters = {\"query\": self.Query, \"view\": \"Complete\", \"date\": date, \"field\": field, \"cursor\": cursor}\n",
    "            article_response = requests.get(url, headers=headers, params= parameters)\n",
    "            article_response_json = article_response.json()\n",
    "            if article_response_json['search-results'].get('entry') is not None:\n",
    "                scopus_articles_df = pd.DataFrame.from_dict(pd.json_normalize(article_response_json, meta=[\"search-results\"], record_path=[\"search-results\", \"entry\"]), orient=\"columns\")\n",
    "                date_title_description_df = scopus_articles_df[[\"prism:coverDate\", \"dc:title\", \"dc:description\"]]\n",
    "                date_title_description_df.columns = ['Date','Title','Content']\n",
    "                pd.to_datetime(date_title_description_df['Date'], format = \"%Y-%m-%d\")\n",
    "                date_title_description_df.sort_values(by='Date')\n",
    "                date_title_description_df = date_title_description_df.set_index('Date')\n",
    "                scopus_search_appended_df = scopus_search_appended_df.append(date_title_description_df)\n",
    "                cursor = article_response_json['search-results']['cursor']['@next']\n",
    "        return scopus_search_appended_df\n",
    "   \n",
    "    @pn.depends('file_name', watch=True)\n",
    "    def update_sample_df(self, event=None):\n",
    "        self.sample_df = pd.DataFrame(self.search_request_funt())\n",
    "        \n",
    "    @pn.depends(\"sample_df\", watch=True)\n",
    "    def _update_table(self):\n",
    "        if hasattr(self, \"table\"):\n",
    "            self.table.value = self.sample_df.head(10)\n",
    "    \n",
    "    def freq_plot_funt(self):\n",
    "        scopus_search_appended_df = self.search_request_funt()\n",
    "        scopus_search_appended_df = scopus_search_appended_df.reset_index()\n",
    "        scopus_search_appended_df['Date'] = pd.to_datetime(scopus_search_appended_df['Date'], format = \"%Y-%m-%d\")\n",
    "        scopus_search_appended_year = scopus_search_appended_df.Date.dt.year.unique()\n",
    "        scopus_search_appended_count = scopus_search_appended_df['Date'].groupby(scopus_search_appended_df.Date.dt.year).agg('count')\n",
    "        scopus_search_appended_count_df = pd.DataFrame(scopus_search_appended_count)\n",
    "        scopus_search_appended_count_df.columns = ['Count']\n",
    "        scopus_search_appended_count_df = scopus_search_appended_count_df.reset_index() \n",
    "        plot = scopus_search_appended_count_df.hvplot.line(title= \"Total Count per Year for the Word '\" + self.Query + \"' used in Academic Articles\", \n",
    "                                    x = \"Date\", \n",
    "                                    y = 'Count',\n",
    "                                    invert = False, \n",
    "                                    height = 600,\n",
    "                                    width = 800\n",
    "                                    )\n",
    "        return plot\n",
    "\n",
    "\n",
    "    def view(self):\n",
    "        return pn.Row(pn.Column(\n",
    "            \"## Generate and Download Data from Scopus API Request\",\n",
    "            pn.Row(\n",
    "                pn.Param(self, parameters=['Query', 'Year_Range', 'generate_sample_df'], show_name=False, widgets={\"generate_sample_df\": {\"button_type\": \"primary\"}}),\n",
    "                pn.Column(self.param.file_name, self.download, align='end', margin=(10,5,5,5)),\n",
    "            ),\n",
    "            \"**Scopus DataFrame (10 Rows)**\",\n",
    "            self.table), self.freq_plot_funt)\n",
    "\n",
    "\n",
    "    \n",
    "class word_dash(param.Parameterized):\n",
    "\n",
    "    # Y value multiselectors\n",
    "    Column_Selector = param.ObjectSelector(default = 'Title', objects=['Title', 'Content'])\n",
    "    \n",
    "    # Word Count Slider\n",
    "    Word_Slider = param.Integer(15, bounds=(5,50))\n",
    "\n",
    "    # Stop word addition\n",
    "    Text_Input = param.String(default='', doc= 'Type Words Here, Seperated by a Space')\n",
    "    \n",
    "    File_Input = param.Parameter()\n",
    "    \n",
    "    data = param.DataFrame()\n",
    "    \n",
    "    generate_sample_df = param.Action(lambda self: self.update_sample_df, label=\"Generate Data\", doc=\"\"\" An action callback which will update the sample_df.\"\"\")\n",
    "    \n",
    "    def __init__(self, **params):\n",
    "        self.param.File_Input.default = pn.widgets.FileInput()\n",
    "        super().__init__(**params)\n",
    "        self._update_table()\n",
    "        self.image_pane = pn.pane.JPG(height= 400, width = 400)\n",
    "        self.table = pn.widgets.DataFrame(self.data, height = 400, width = 400)\n",
    "        self.plotly_pane = pn.pane.Plotly(height=400, width = 400)\n",
    "    \n",
    "    @pn.depends(\"File_Input.value\", watch=True)\n",
    "    def _parse_file_input(self):\n",
    "        value = self.File_Input.value\n",
    "        if value:\n",
    "            string_io = io.StringIO(value.decode(\"utf8\"))\n",
    "            self.data = pd.read_csv(string_io)\n",
    "        else:\n",
    "            return\n",
    "    \n",
    "    @pn.depends(\"data\", \"Column_Selector\", \"Word_Slider\", \"Text_Input\", watch = True)\n",
    "    def dataframe_to_string(self):\n",
    "            scopus = self.data\n",
    "            if scopus is None:\n",
    "                return\n",
    "            else:\n",
    "                if self.Column_Selector == 'Content':\n",
    "                    for row in scopus:\n",
    "                        big_string = ''.join(str(scopus['Content']))\n",
    "                    sw = set(stopwords.words('english'))\n",
    "                    regex = re.compile(\"[^a-zA-Z ]\")\n",
    "                    wordlist = re.sub(\"[^\\w]\", \" \",  self.Text_Input).split()\n",
    "                    sw_addons = {'using', 'via', 'based', 'nan', 'date', 'used', 'b', 'tio', 'nanote'}\n",
    "                    sw_addons.update(wordlist)\n",
    "                    re_clean = regex.sub('', big_string)\n",
    "                    words = word_tokenize(re_clean)\n",
    "                    lem = [lemmatizer.lemmatize(word) for word in words]\n",
    "                    output = [word.lower() for word in lem if word.lower() not in sw.union(sw_addons)]\n",
    "                    full_string = ' '.join(output)\n",
    "                    wc_content = WordCloud(width=800, height=600, background_color=\"white\", max_words= self.Word_Slider).generate(full_string)\n",
    "                    self.image_pane.object = wc_content.to_image(format = 'jpg')\n",
    "                    self.plotly_pane.object = wc_content.to_image(format = 'jpg')\n",
    "                else:\n",
    "                    for row in scopus:\n",
    "                        big_string = ''.join(str(scopus['Title']))\n",
    "                    sw = set(stopwords.words('english'))\n",
    "                    regex = re.compile(\"[^a-zA-Z ]\")\n",
    "                    wordlist = re.sub(\"[^\\w]\", \" \",  self.Text_Input).split()\n",
    "                    sw_addons = {'using', 'via', 'based', 'nan', 'date', 'used', 'b', 'tio', 'nanote'}\n",
    "                    sw_addons.update(wordlist)\n",
    "                    re_clean = regex.sub('', big_string)\n",
    "                    words = word_tokenize(re_clean)\n",
    "                    lem = [lemmatizer.lemmatize(word) for word in words]\n",
    "                    output = [word.lower() for word in lem if word.lower() not in sw.union(sw_addons)]\n",
    "                    full_string = ' '.join(output)\n",
    "                    wc_content = WordCloud(width=800, height=600, background_color=\"white\", max_words= self.Word_Slider).generate(full_string)\n",
    "                    self.image_pane.object = wc_content.to_image(format = 'jpg')\n",
    "                    self.plotly_pane.object = wc_content.to_image(format = 'jpg')\n",
    "    \n",
    "    @pn.depends(\"data\", watch=True)\n",
    "    def _update_table(self):\n",
    "        if hasattr(self, \"table\"):\n",
    "            self.table.value = self.data.head(10)\n",
    "\n",
    "    def view(self):\n",
    "        return pn.Column(self.File_Input, \n",
    "                         pn.Param(self, parameters = ['Column_Selector', 'Word_Slider', 'Text_Input', 'generate_sample_df'], show_name = False, widgets = {\n",
    "                             \"Column_Selector\": {\n",
    "                                 \"type\": pn.widgets.Select(name = 'Title', options=['Title', 'Content'])\n",
    "                             },\n",
    "                             \"Word_Slider\": {\n",
    "                                 \"type\": pn.widgets.IntSlider(name = 'Total Words', start=0, end= 50, step = 1, value = 10, value_throttled= 10),\n",
    "                                 \"throttled\": True,\n",
    "                             },\n",
    "                         }), \n",
    "                         \"**Wordcloud**\", \n",
    "                         self.image_pane, self.table, self.plotly_pane\n",
    "                        )\n",
    "        \n",
    "search = search_scopus_dash(name='Query Search Request Below')\n",
    "\n",
    "search_view = search.view()\n",
    "\n",
    "word = word_dash()\n",
    "\n",
    "word_view = word.view()\n",
    "\n",
    "search_view_tab = pn.template.MaterialTemplate(site=\"Panel\", title=\"Download and Upload CSV File\", main=[search_view, word_view]);\n",
    "\n",
    "#search_dash_tab = pn.Column('# Download Dataframe and Excel Files Here','### This can take take between a few minutes to several minutes depending on the data size requested', pn.Row(pn.Column(search.param)), background='#f0f0f0')\n",
    "\n",
    "#freq_plot_tab = pn.Column('# Frequency Plot', pn.Row(search.freq_plot_funt), background='#f0f0f0')\n",
    "\n",
    "#word_cloud_tab = pn.Column('# Word Cloud', pn.Column(word.controls, word.dataframe_to_string), background='#f0f0f0')\n",
    "\n",
    "#all_tabs = pn.Tabs(('Data Selection', search_dash_tab), ('Frequency Plot', freq_plot_tab), ('Word Cloud', word_cloud_tab))\n",
    "search_view_tab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "search_scopus_dash().search_request_funt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
