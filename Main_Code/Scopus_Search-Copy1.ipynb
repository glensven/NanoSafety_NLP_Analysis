{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use multiple Scopus Author IDs to retrieve lists of articles by author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from config import api_key\n",
    "from pandas.io.json import json_normalize  \n",
    "import nltk\n",
    "import re\n",
    "import io\n",
    "from nltk.corpus import stopwords, reuters\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from wordcloud import WordCloud\n",
    "import panel as pn\n",
    "import panel.widgets \n",
    "from pathlib import Path\n",
    "from panel.interact import interact\n",
    "import hvplot.pandas\n",
    "import param\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML\n",
    "import time\n",
    "import datetime\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "pn.extension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare necessary parameters for Scopus request API search tool\n",
    "url = \"http://api.elsevier.com/content/search/scopus?\" + \"cursor=*\"\n",
    "headers = {\"X-ELS-APIKey\": api_key, 'Accept':'application/json'}\n",
    "view = \"Complete\"\n",
    "field = [\"dc:description\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Declare the timeframe to search by start and end years\n",
    "# Year is the lowest granularity for this search function\n",
    "start_year = 2008\n",
    "end_year = 2009\n",
    "if start_year == end_year:\n",
    "    date = str(start_year)\n",
    "else: \n",
    "    date = str(start_year) + \"-\" + str(end_year)\n",
    "\n",
    "# Generate a lists of dates for the requested timeframe\n",
    "date_list = []\n",
    "for date in range(start_year, end_year + 1):\n",
    "    date_list.append(int(date))\n",
    "    \n",
    "#date_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input the query search term\n",
    "query = \"Nanosafety\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[88]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test search function to determine the total results from the Get Request for the Specified Date Range\n",
    "total_results = []\n",
    "date_list = []\n",
    "for date in range(start_year, end_year + 1):\n",
    "    date_list.append(int(date))\n",
    "    \n",
    "def total_results_funt(start_year, end_year):\n",
    "    parameters = {\"query\": query, \"view\": view, \"date\": str(start_year) + \"-\" + str(end_year), }\n",
    "    article_response = requests.get(url, headers=headers, params=parameters)\n",
    "    article_response_json = article_response.json()\n",
    "    total_results.append(int(article_response_json['search-results']['opensearch:totalResults']))\n",
    "    return total_results\n",
    "\n",
    "total_results = total_results_funt(start_year, end_year)\n",
    "total_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search request function \n",
    "currentDateTime = datetime.datetime.now()\n",
    "date = currentDateTime.date()\n",
    "current_year = int(date.strftime(\"%Y\"))\n",
    "\n",
    "start_year = pn.widgets.IntInput(name='Select Starting Year', value=2005, step=1, start = 1900, end= 2021 )\n",
    "\n",
    "end_year = pn.widgets.IntInput(name='Select Starting Year', value=2006, step=1, start = 1900, end= 2021 )\n",
    "\n",
    "@pn.depends(start_year, end_year)\n",
    "def search_request_funt(start_year, end_year):\n",
    "    \n",
    "    scopus_search_appended_df = pd.DataFrame()\n",
    "    \n",
    "    if start_year == end_year:\n",
    "        date = str(start_year)\n",
    "    else: \n",
    "        date = str(start_year) + \"-\" + str(end_year)\n",
    "    cursor = \"*\"\n",
    "    field = \"prism:coverDate,dc:title,dc:description\"\n",
    "    url = \"http://api.elsevier.com/content/search/scopus?\"\n",
    "    \n",
    "    parameters = {\"query\": query, \"view\": \"Complete\", \"date\": date, \"field\": field, \"cursor\": cursor}\n",
    "    article_response = requests.get(url, headers=headers, params=parameters)\n",
    "    article_response_json = article_response.json()\n",
    "    #total_results = int(article_response_json['search-results']['opensearch:totalResults'])\n",
    "    while article_response_json['search-results'].get('entry') is not None:\n",
    "        url = \"http://api.elsevier.com/content/search/scopus?\"\n",
    "        parameters = {\"query\": query, \"view\": \"Complete\", \"date\": date, \"field\": field, \"cursor\": cursor}\n",
    "        article_response = requests.get(url, headers=headers, params= parameters)\n",
    "        article_response_json = article_response.json()\n",
    "        if article_response_json['search-results'].get('entry') is not None:\n",
    "            scopus_articles_df = pd.DataFrame.from_dict(pd.json_normalize(article_response_json, meta=[\"search-results\"], record_path=[\"search-results\", \"entry\"]), orient=\"columns\")\n",
    "            date_title_description_df = scopus_articles_df[[\"prism:coverDate\", \"dc:title\", \"dc:description\"]]\n",
    "            date_title_description_df.columns = ['Date','Title','Content']\n",
    "            pd.to_datetime(date_title_description_df['Date'], format = \"%Y-%m-%d\")\n",
    "            date_title_description_df.sort_values(by='Date')\n",
    "            date_title_description_df = date_title_description_df.set_index('Date')\n",
    "            scopus_search_appended_df = scopus_search_appended_df.append(date_title_description_df)\n",
    "            df_widget = pn.widgets.DataFrame(scopus_search_appended_df, name='DataFrame')\n",
    "            cursor = article_response_json['search-results']['cursor']['@next']\n",
    "    return df_widget\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save a csv of the dataframe\n",
    "#search_request_funt(query, start_year, end_year).to_csv(\"Scopus_Search_\" + \"_\" + query + \"_\" + str(start_year) + \"_\" + str(end_year) + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-12-31</td>\n",
       "      <td>Optical phonon mixing in bilayer graphene with...</td>\n",
       "      <td>Pristine bilayer graphene is a centrosymmetric...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-12-31</td>\n",
       "      <td>Weak-coupling study of decoherence of a qubit ...</td>\n",
       "      <td>We study the decoherence of a qubit weakly cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-12-31</td>\n",
       "      <td>Anisotropic electron-phonon coupling on a two-...</td>\n",
       "      <td>Angle-resolved photoemission reveals that the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-12-31</td>\n",
       "      <td>Quantum dynamics of the Eley-Rideal hydrogen f...</td>\n",
       "      <td>Eley - Rideal formation of hydrogen molecules ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-12-31</td>\n",
       "      <td>The derivation of the von Klitzing's constant</td>\n",
       "      <td>The Hall resistivity is found to become a func...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date                                              Title  \\\n",
       "0  2009-12-31  Optical phonon mixing in bilayer graphene with...   \n",
       "1  2009-12-31  Weak-coupling study of decoherence of a qubit ...   \n",
       "2  2009-12-31  Anisotropic electron-phonon coupling on a two-...   \n",
       "3  2009-12-31  Quantum dynamics of the Eley-Rideal hydrogen f...   \n",
       "4  2009-12-31      The derivation of the von Klitzing's constant   \n",
       "\n",
       "                                             Content  \n",
       "0  Pristine bilayer graphene is a centrosymmetric...  \n",
       "1  We study the decoherence of a qubit weakly cou...  \n",
       "2  Angle-resolved photoemission reveals that the ...  \n",
       "3  Eley - Rideal formation of hydrogen molecules ...  \n",
       "4  The Hall resistivity is found to become a func...  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set file path\n",
    "scopus_search_path = Path(\"Scopus_Search_\" + \"_\" + query + \"_\" + str(start_year) + \"_\" + str(end_year) + \".csv\", header = 0)\n",
    "# Read CSV to DataFrame\n",
    "query_df = pd.read_csv(scopus_search_path)\n",
    "query_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_nanosafety_df = pd.read_csv(Path(\"Scopus_Search_Nanosafety_2005_2021.csv\", header = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date Range Slider\n",
    "year_slider = pn.widgets.IntRangeSlider(name='Timeframe', width=300, start=1990, end=2021, value=(2005, 2020))\n",
    "\n",
    "@pn.depends(year_slider)\n",
    "def freq_plot_funt(year_slider):\n",
    "    total_results = []\n",
    "    date_list = []\n",
    "    for date in range(year_slider[0], year_slider[1] + 1):\n",
    "        date_list.append(int(date))\n",
    "    for i in date_list:\n",
    "        parameters = {\"query\": query, \"view\": \"Standard\", \"date\": str(i), \"count\": 25, \"start\": 0}\n",
    "        article_response = requests.get(url, headers=headers, params=parameters)\n",
    "        article_response_json = article_response.json()\n",
    "        total_results.append(int(article_response_json['search-results']['opensearch:totalResults']))\n",
    "    # Create an annual frequency bar plot for query search\n",
    "    frequency_df = pd.DataFrame([date_list, total_results]).T\n",
    "    frequency_df.columns = ['Year', 'Total Count per Year']\n",
    "    plot = frequency_df.hvplot.line(title= \"Total Count per Year for the Word '\" + query + \"' used in Academic Articles\", \n",
    "                                x = \"Year\", \n",
    "                                y = 'Total Count per Year',\n",
    "                                invert = False, \n",
    "                                height = 400,\n",
    "                                width = 800\n",
    "                                )\n",
    "    return plot\n",
    "freq_plot = pn.Column(pn.Row(pn.WidgetBox(year_slider), pn.Column(freq_plot_funt)))\n",
    "#freq_plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching server at http://localhost:54401\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bokeh.server.server.Server at 0x1ef1655e948>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Y value multiselectors\n",
    "column_selector = pn.widgets.Select(name='Select for a Title or Abstract', value = 'Title', options=['Title', 'Content'])\n",
    "\n",
    "# Word Count Slider\n",
    "word_slider = pn.widgets.IntSlider(name='Max Words', start=5, end=50, step=1, value=15)\n",
    "\n",
    "# Stop word addition\n",
    "text_input = pn.widgets.TextInput(name='Enter Additional Words to Ignore', placeholder='Type Words Here, Seperated by a Space')\n",
    "# Dynamic Plots\n",
    "\n",
    "# Convert dataframe Title column to string text\n",
    "@pn.depends(column_selector, word_slider, text_input)\n",
    "def dataframe_to_string(column_selector, word_slider, text_input):\n",
    "    if column_selector == 'Content':\n",
    "        for row in query_df:\n",
    "            big_string = ''.join(str(query_df['Content']))\n",
    "        sw = set(stopwords.words('english'))\n",
    "        regex = re.compile(\"[^a-zA-Z ]\")\n",
    "        wordlist = re.sub(\"[^\\w]\", \" \",  text_input).split()\n",
    "        sw_addons = {'using', 'via', 'based', 'nan', 'date', 'used', 'b', 'tio', 'nanote'}\n",
    "        sw_addons.update(wordlist)\n",
    "        re_clean = regex.sub('', big_string)\n",
    "        words = word_tokenize(re_clean)\n",
    "        lem = [lemmatizer.lemmatize(word) for word in words]\n",
    "        output = [word.lower() for word in lem if word.lower() not in sw.union(sw_addons)]\n",
    "        full_string = ' '.join(output)\n",
    "        wc_content = WordCloud(width=800, height=600, background_color=\"white\", max_words= word_slider).generate(full_string)\n",
    "        image_1 = wc_content.to_image()\n",
    "        return image_1\n",
    "    else:\n",
    "        for row in query_df:\n",
    "            big_string = ''.join(str(query_df['Title']))\n",
    "        sw = set(stopwords.words('english'))\n",
    "        regex = re.compile(\"[^a-zA-Z ]\")\n",
    "        wordlist = re.sub(\"[^\\w]\", \" \",  text_input).split()\n",
    "        sw_addons = {'using', 'via', 'based', 'nan', 'date', 'used', 'b', 'tio', 'nanote'}\n",
    "        sw_addons.update(wordlist)\n",
    "        re_clean = regex.sub('', big_string)\n",
    "        words = word_tokenize(re_clean)\n",
    "        lem = [lemmatizer.lemmatize(word) for word in words]\n",
    "        output = [word.lower() for word in lem if word.lower() not in sw.union(sw_addons)]\n",
    "        full_string = ' '.join(output)\n",
    "        wc_content = WordCloud(width=800, height=600, background_color=\"white\", max_words= word_slider).generate(full_string)\n",
    "        image_2 = wc_content.to_image()\n",
    "        return image_2\n",
    "\n",
    "data_tab = pn.Column('# Download Dataframe and Excel Files Here', pn.Row(pn.WidgetBox(start_year, end_year), pn.Column(search_request_funt)), background='#f0f0f0')\n",
    "word_cloud_tab = pn.Column('# Word Cloud', pn.Row(pn.WidgetBox(column_selector, word_slider, text_input), pn.Column(dataframe_to_string)), background='#f0f0f0')\n",
    "freq_plot_tab = pn.Column('# Frequency Plot', pn.WidgetBox(year_slider), freq_plot_funt, background='#f0f0f0')\n",
    "all_tabs = pn.Tabs(('Data Selection', data_tab), ( 'Frequency Plot', freq_plot_tab), ('Word Cloud', word_cloud_tab))\n",
    "all_tabs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
