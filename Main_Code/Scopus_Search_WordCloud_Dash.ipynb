{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use multiple Scopus Author IDs to retrieve lists of articles by author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from config import api_key\n",
    "from pandas.io.json import json_normalize  \n",
    "import nltk\n",
    "import re\n",
    "import io\n",
    "from nltk.corpus import stopwords, reuters\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from wordcloud import WordCloud\n",
    "import panel as pn\n",
    "import panel.widgets \n",
    "from pathlib import Path\n",
    "from panel.interact import interact\n",
    "import param\n",
    "import time\n",
    "import datetime as dt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import multidict as multidict\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "pn.extension()\n",
    "import hvplot.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching server at http://localhost:55472\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bokeh.server.server.Server at 0x1c20390a3c8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "class search_scopus_dash(param.Parameterized):\n",
    "    \n",
    "    # Search Term Input to query search, default is \"Nanosafety\"\n",
    "    Query  = param.String(default=\"Nanosafety\", doc=\"Insert query term(s)\")\n",
    "    \n",
    "    # Year range selection parameter for search\n",
    "    Year_Range = param.Range((2005, 2010), bounds=(1970, 2021))\n",
    "    \n",
    "    # Action param to initiate search\n",
    "    generate_sample_df = param.Action(lambda self: self.update_sample_df(), label=\"Generate Data\", doc=\"\"\"\n",
    "      An action callback which will update the sample_df.\"\"\")\n",
    "    \n",
    "    # Dataframe param to store data from scopus search API\n",
    "    sample_df = param.DataFrame()\n",
    "    \n",
    "    file_name = param.String(default=\"data.csv\", doc=\"\"\"\n",
    "      The filename to save to.\"\"\")\n",
    "    \n",
    "    # Initiate desired parameters\n",
    "    def __init__(self, **params):\n",
    "        super().__init__(**params)\n",
    "        self.search_request_funt()\n",
    "        self.update_sample_df()        \n",
    "        self.download = pn.widgets.FileDownload(name=\"Download Data\", filename=self.file_name, callback=self._download_callback, button_type=\"primary\")\n",
    "        self.table = pn.widgets.DataFrame(self.sample_df, height=300)\n",
    "        \n",
    "    # Upate filename in download widget  \n",
    "    @pn.depends('file_name', watch=True)\n",
    "    def _update_filename(self):\n",
    "        self.download.filename = self.file_name\n",
    "    \n",
    "    # Download function for excel file\n",
    "    def _download_callback(self):\n",
    "        \"\"\"\n",
    "        A FileDownload callback will return a file-like object which can be serialized\n",
    "        and sent to the client.\n",
    "        \"\"\"\n",
    "        self.download.filename = self.file_name\n",
    "        sio = io.StringIO()\n",
    "        self.sample_df.to_csv(sio, index=False)\n",
    "        sio.seek(0)\n",
    "        return sio\n",
    "    \n",
    "    \n",
    "    # Scopus API search request function to generate dataframe with columns for date, title, and abstrast with queried search term b/t selected year range\n",
    "    @param.depends('file_name', \"Query\", \"Year_Range\", watch=True)\n",
    "    def search_request_funt(self):\n",
    "    \n",
    "        scopus_search_appended_df = pd.DataFrame()\n",
    "    \n",
    "        if self.Year_Range[0] == self.Year_Range[1]:\n",
    "            date = str(self.Year_Range[0])\n",
    "        else: \n",
    "            date = str(self.Year_Range[0]) + \"-\" + str(self.Year_Range[1])\n",
    "        # Declare necessary parameters for Scopus request API search tool\n",
    "        cursor = \"*\"\n",
    "        field = \"prism:coverDate,dc:title,dc:description\"\n",
    "        url = \"http://api.elsevier.com/content/search/scopus?\"\n",
    "        headers = {\"X-ELS-APIKey\": api_key, 'Accept':'application/json'}\n",
    "        parameters = {\"query\": self.Query, \"view\": \"Complete\", \"date\": date, \"field\": field, \"cursor\": cursor}\n",
    "        article_response = requests.get(url, headers=headers, params=parameters)\n",
    "        article_response_json = article_response.json()\n",
    "        total_results = int(article_response_json['search-results']['opensearch:totalResults'])\n",
    "        # Loop to grab all API data\n",
    "        while article_response_json['search-results'].get('entry') is not None:\n",
    "            url = \"http://api.elsevier.com/content/search/scopus?\"\n",
    "            parameters = {\"query\": self.Query, \"view\": \"Complete\", \"date\": date, \"field\": field, \"cursor\": cursor}\n",
    "            article_response = requests.get(url, headers=headers, params= parameters)\n",
    "            article_response_json = article_response.json()\n",
    "            if article_response_json['search-results'].get('entry') is not None:\n",
    "                scopus_articles_df = pd.DataFrame.from_dict(json_normalize(article_response_json, meta=[\"search-results\"], record_path=[\"search-results\", \"entry\"]), orient=\"columns\")\n",
    "                date_title_description_df = scopus_articles_df[[\"prism:coverDate\", \"dc:title\", \"dc:description\"]]\n",
    "                date_title_description_df.columns = ['Date','Title','Content']\n",
    "                pd.to_datetime(date_title_description_df['Date'], format = \"%Y-%m-%d\")\n",
    "                date_title_description_df.sort_values(by='Date')\n",
    "                #date_title_description_df = date_title_description_df.set_index('Date')\n",
    "                scopus_search_appended_df = scopus_search_appended_df.append(date_title_description_df)\n",
    "                cursor = article_response_json['search-results']['cursor']['@next']\n",
    "        return scopus_search_appended_df\n",
    "\n",
    "    # Update dataframe with results\n",
    "    @pn.depends('file_name', watch=True)\n",
    "    def update_sample_df(self, event=None):\n",
    "        self.sample_df = pd.DataFrame(self.search_request_funt())\n",
    "        \n",
    "    @pn.depends(\"sample_df\", watch=True)\n",
    "    def _update_table(self):\n",
    "        if hasattr(self, \"table\"):\n",
    "            self.table.value = self.sample_df\n",
    "            \n",
    "    def save_sample_data(self, event=None):\n",
    "        if not self.sample_df is None:\n",
    "            self.sample_df\n",
    "    \n",
    "    def freq_plot_funt(self):\n",
    "        scopus_search_appended_df = self.sample_df\n",
    "        scopus_search_appended_df = scopus_search_appended_df.reset_index()\n",
    "        scopus_search_appended_df['Date'] = pd.to_datetime(scopus_search_appended_df['Date'], format = \"%Y-%m-%d\")\n",
    "        scopus_search_appended_year = scopus_search_appended_df.Date.dt.year.unique()\n",
    "        scopus_search_appended_count = scopus_search_appended_df['Date'].groupby(scopus_search_appended_df.Date.dt.year).agg('count')\n",
    "        scopus_search_appended_count_df = pd.DataFrame(scopus_search_appended_count)\n",
    "        scopus_search_appended_count_df.columns = ['Count']\n",
    "        scopus_search_appended_count_df = scopus_search_appended_count_df.reset_index() \n",
    "        plot = scopus_search_appended_count_df.hvplot.line(title= \"Total Count per Year for the Word '\" + self.Query + \"' used in Academic Articles\", \n",
    "                                    x = \"Date\", \n",
    "                                    y = 'Count',\n",
    "                                    invert = False, \n",
    "                                    height = 600,\n",
    "                                    width = 800\n",
    "                                    )\n",
    "        return plot\n",
    "    \n",
    "    def view(self):\n",
    "            return pn.Row(pn.Column(\n",
    "            \"## Generate and Download Data\",\n",
    "            pn.Row(\n",
    "                pn.Param(self, parameters=['Query', 'Year_Range', 'generate_sample_df'], show_name=False, widgets={\"generate_sample_df\": {\"button_type\": \"primary\"}}),\n",
    "                pn.Column(self.param.file_name, self.download, align='end', margin=(10,5,5,5)),\n",
    "            ),\n",
    "            \"**Sample data (10 Rows)**\",\n",
    "            self.table), self.freq_plot_funt\n",
    "        )\n",
    "\n",
    "        \n",
    "\n",
    "class word_dash(param.Parameterized):\n",
    "    \n",
    "    # Word Count Slider\n",
    "    Word_Slider = param.Integer(15, bounds=(5,50))\n",
    "\n",
    "    # Stop word addition\n",
    "    Text_Input = param.String(default='', doc= 'Type Words Here, Seperated by a Space')\n",
    "    \n",
    "    File_Input = param.Parameter()\n",
    "    \n",
    "    data = param.DataFrame()\n",
    "    \n",
    "    freq_title_data = param.DataFrame()\n",
    "    \n",
    "    freq_content_data = param.DataFrame()\n",
    "    \n",
    "\n",
    "    \n",
    "    # Collation Count Slider\n",
    "    CT_Slider = param.Integer(30, bounds=(0,60))\n",
    "    \n",
    "    \n",
    "    def __init__(self, **params):\n",
    "        self.param.File_Input.default = pn.widgets.FileInput()\n",
    "        blank_title = px.imshow(np.full((600, 600, 3), 255, dtype = np.uint8), title= \"Upload File to Generate Title WordCloud\").update_xaxes(showticklabels=False).update_yaxes(showticklabels=False)\n",
    "        blank_content = px.imshow(np.full((600, 600, 3), 255, dtype = np.uint8), title= \"Upload File to Generate Content WordCloud\").update_xaxes(showticklabels=False).update_yaxes(showticklabels=False)\n",
    "        super().__init__(**params)\n",
    "        self.plotly_pane_title = pn.pane.Plotly(blank_title, background= 'white')\n",
    "        self.plotly_pane_content = pn.pane.Plotly(blank_content, background = 'white')\n",
    "        self.title_str_pane = pn.pane.Str(max_width = 600, height_policy = \"fit\")\n",
    "        self.content_str_pane = pn.pane.Str(max_width = 600, height_policy = \"fit\")\n",
    "        self.freq_title_df = pn.pane.DataFrame()\n",
    "        \n",
    "    @pn.depends(\"File_Input.value\", watch=True)\n",
    "    def _parse_file_input(self):\n",
    "        value = self.File_Input.value\n",
    "        if value:\n",
    "            string_io = io.StringIO(value.decode(\"utf8\"))\n",
    "            self.data = pd.read_csv(string_io)\n",
    "        else:\n",
    "            return\n",
    "    \n",
    "    @pn.depends(\"data\", \"Word_Slider\", \"Text_Input\", 'CT_Slider', watch = True)\n",
    "    def dataframe_to_string(self):\n",
    "            scopus = self.data\n",
    "            if scopus is None:\n",
    "                return\n",
    "            else:\n",
    "                for row in scopus:\n",
    "                    big_string_title = ''.join(str(scopus['Title']))\n",
    "                    big_string_content = ''.join(str(scopus['Content']))\n",
    "                sw = set(stopwords.words('english'))\n",
    "                regex = re.compile(\"[^a-zA-Z ]\")\n",
    "                wordlist = re.sub(\"[^\\w]\", \" \",  self.Text_Input).split()\n",
    "                sw_addons = {'using', 'via', 'based', 'nan', 'date', 'used', 'b', 'tio', 'nanote'}\n",
    "                sw_addons.update(wordlist)\n",
    "                re_clean_title = regex.sub('', big_string_title)\n",
    "                re_clean_content = regex.sub('', big_string_content)\n",
    "                words_title = word_tokenize(re_clean_title)\n",
    "                words_content = word_tokenize(re_clean_content)\n",
    "                lem_title = [lemmatizer.lemmatize(word) for word in words_title]\n",
    "                lem_content = [lemmatizer.lemmatize(word) for word in words_content]\n",
    "                output_title = [word.lower() for word in lem_title if word.lower() not in sw.union(sw_addons)]\n",
    "                output_content = [word.lower() for word in lem_content if word.lower() not in sw.union(sw_addons)]\n",
    "                full_string_title = ' '.join(output_title)\n",
    "                full_string_content = ' '.join(output_content)\n",
    "                wc_title = WordCloud(background_color=\"white\", min_word_length= 3, normalize_plurals=True, collocation_threshold= self.CT_Slider, max_words= self.Word_Slider).generate(full_string_title)\n",
    "                wc_content = WordCloud(background_color=\"white\", min_word_length= 3, normalize_plurals=True, collocation_threshold= self.CT_Slider, max_words= self.Word_Slider).generate(full_string_content)\n",
    "                \n",
    "                fig_title = px.imshow(wc_title)\n",
    "                fig_title.update_xaxes(showticklabels=False)\n",
    "                fig_title.update_yaxes(showticklabels=False)\n",
    "                fig_title.update_layout(title_font_color=\"black\", title_font_family= \"Arial\", title_font_size= 45, title_x = 0.5, title_y= 0.95)\n",
    "                \n",
    "                \n",
    "                fig_content = px.imshow(wc_content)\n",
    "                fig_content.update_xaxes(showticklabels=False)\n",
    "                fig_content.update_yaxes(showticklabels=False)\n",
    "                fig_content.update_layout(title_font_color=\"black\", title_font_family= \"Arial\", title_font_size= 45, title_x = 0.5, title_y= 0.95)\n",
    "            \n",
    "                self.plotly_pane_title.object = fig_title\n",
    "                self.plotly_pane_content.object = fig_content\n",
    "                \n",
    "    def view(self):\n",
    "        return pn.Column(pn.Row(pn.Column(\"*Select the saved excel data file here*\", self.File_Input), \n",
    "                         pn.Param(self, parameters = ['Column_Selector', 'Word_Slider', 'CT_Slider', 'Text_Input',], show_name = False, widgets = {\n",
    "                             \"Column_Selector\": {\n",
    "                                 \"type\": pn.widgets.Select(name = 'Title', options=['Title', 'Content'])\n",
    "                             },\n",
    "                             \"Word_Slider\": {\n",
    "                                 \"type\": pn.widgets.IntSlider(name = 'Total Words', start=0, end= 50, step = 1, value = 10, value_throttled= 10),\n",
    "                                 \"throttled\": True,\n",
    "                             },\n",
    "                             \"CT_Slider\": {\n",
    "                                 \"type\": pn.widgets.IntSlider(name = 'Collocation Threshold', start=0, end= 60, step = 1, value = 30, value_throttled= 10),\n",
    "                                 \"throttled\": True,\n",
    "                             }\n",
    "                         })),\n",
    "                         pn.Row(pn.Column(pn.Card(self.plotly_pane_title, title = \"WordCloud of Titles\", background='WhiteSmoke')),\n",
    "                                pn.Column(pn.Card(self.plotly_pane_content, title = \"WordCloud of Abstracts\", background='WhiteSmoke')\n",
    "                                          ))\n",
    "                        )\n",
    "        \n",
    "# Save dashboard for visualization\n",
    "\n",
    "search = search_scopus_dash()\n",
    "\n",
    "search_view = search.view()\n",
    "\n",
    "word = word_dash()\n",
    "\n",
    "word_view = word.view()\n",
    "\n",
    "all_tabs = pn.Tabs(('Search', search_view), ('Word Cloud', word_view))\n",
    "\n",
    "all_tabs_view = pn.template.MaterialTemplate(site=\"Search Panel\", title=\"Download Search Data, Generate CSV File, Produce WordClouds\", main=[all_tabs]);\n",
    "\n",
    "all_tabs_view.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `CountVectorizer` not found.\n"
     ]
    }
   ],
   "source": [
    "?CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_1 = [('re', 148), ('make', 117), ('ve', 106), ('said', 95), ('able', 88)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('re', 148), ('make', 117), ('ve', 106), ('said', 95), ('able', 88)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
